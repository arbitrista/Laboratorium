{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Estructura del Estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ...\n",
    "\n",
    "Tipologia:\n",
    "- Direcciones\n",
    "- Institutos\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from rich import print\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import duckdb\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pymupdf4llm\n",
    "import pymupdf\n",
    "import fs\n",
    "import collections\n",
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "import dataclasses\n",
    "import typing\n",
    "import pydantic\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the directory two levels above the current notebook's directory to the Python path.\n",
    "## This allows importing modules located in the parent-parent directory, such as \"scripts\".\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path().resolve().parent.parent\n",
    "if str(path) not in sys.path:\n",
    "    sys.path.append(str(path))\n",
    "\n",
    "import scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilationem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Download, store, and convert from pdf to markdown (text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubFS(MemoryFS(), '/datasets')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutionalClassifierURL  = \"https://www.digepres.gob.do/wp-content/uploads/2024/08/Clasificador-Institucional.pdf\"\n",
    "mem_fs = fs.open_fs('mem://')\n",
    "mem_fs.makedirs('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download and write the data to an in-memory file system.\n",
    "response = requests.get(institutionalClassifierURL)\n",
    "if response.status_code == 200:\n",
    "    with mem_fs.open(\"datasets/Clasificador-Institucional.pdf\", 'wb') as handler:\n",
    "        handler.write(response.content)\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ...\n",
      "[                                        ] (0/49[                                        ] ( 1/49[                                        ] ( 1/49[=                                       ] ( 2/4[==                                      ] ( 3/49[===                                     ] ( 4/4[====                                    ] ( 5/4[====                                    ] ( 6/49[=====                                   ] ( 7/4[======                                  ] ( 8/49[=======                                 ] ( 9/4[========                                ] (10/4[========                                ] (11/49[=========                               ] (12/4[==========                              ] (13/49[===========                             ] (14/4[============                            ] (15/49[=============                           ] (16/[=============                           ] (17/4[==============                          ] (18/49[===============                         ] (19/4[================                        ] (20/49[=================                       ] (21/[=================                       ] (22/4[==================                      ] (23/49[===================                     ] (24/4[====================                    ] (25/49[=====================                   ] (26/4[======================                  ] (27/4[======================                  ] (28/49[=======================                 ] (29/4[========================                ] (30/49[=========================               ] (31/4[==========================              ] (32/4[==========================              ] (33/49[===========================             ] (34/4[============================            ] (35/49[=============================           ] (36/4[==============================          ] (37/49[===============================         ] (38/[===============================         ] (39/4[================================        ] (40/49[=================================       ] (41/4[==================================      ] (42/49[===================================     ] (43/[===================================     ] (44/4[====================================    ] (45/49[=====================================   ] (46/4[======================================  ] (47/49[======================================= ] (48/4[========================================] (49/49]\n"
     ]
    }
   ],
   "source": [
    "## Convert the PDF data to Markdown text using PyMuPDF and pymupdf4llm.\n",
    "with mem_fs.open(\"datasets/Clasificador-Institucional.pdf\", \"rb\") as handler:\n",
    "        in_memory_file = BytesIO(handler.read())\n",
    "        doc  = pymupdf.open(stream  = in_memory_file, filetype=\"pdf\")\n",
    "\n",
    "text  =  pymupdf4llm.to_markdown(doc)\n",
    "\n",
    "with mem_fs.open(\"datasets/Clasificador-Institucional.md\", \"w\") as handler:\n",
    "        handler.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Parse the data, and generate a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mem_fs.open(\"datasets/Clasificador-Institucional.md\", \"r\") as handler:\n",
    "        lines  = handler.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which lines constitute a 'state organization'?\n",
    "## We have checked the PDF, and the lines that contain twelve '|' are the organizations I want to parse.\n",
    "## collections.Counter([line.count(\"|\") for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataclass\n",
    "@dataclasses.dataclass\n",
    "class Organization:\n",
    "    sector: str\n",
    "    subsector: str\n",
    "    area: str\n",
    "    subarea: str\n",
    "    seccion: str\n",
    "    poderes: str\n",
    "    entidad: str\n",
    "    capitulo: str\n",
    "    subcapitulo: str\n",
    "    unidad_ejecutora: str\n",
    "    denominacion: str\n",
    "\n",
    "    @property\n",
    "    def codigo(self) -> str:\n",
    "        \"\"\"Combine all relevant fields into a single string.\"\"\"\n",
    "        fields_to_combine = [\n",
    "            self.sector, self.subsector, self.area, self.subarea,\n",
    "            self.seccion, self.poderes, self.entidad, self.capitulo,\n",
    "            self.subcapitulo, self.unidad_ejecutora\n",
    "        ]\n",
    "        return \".\".join(filter(None, fields_to_combine))  # Only include non-empty fields\n",
    "    \n",
    "    @property\n",
    "    def is_institution(self) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if the current instance represents an institution.\n",
    "\n",
    "        An institution is identified by having exactly the specified number of \n",
    "        dot separators ('.') in its `codigo`.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if `codigo` has the expected number of dot separators; \n",
    "            otherwise, False.\n",
    "        \"\"\"\n",
    "        NUM_DOT_SEPARATORS_FOR_INSTITUTION = 9\n",
    "        return self.codigo.count('.') == NUM_DOT_SEPARATORS_FOR_INSTITUTION\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Custom string representation including combined fields.\"\"\"\n",
    "        return (f\"Organization(sector={self.sector}, subsector={self.subsector}, area={self.area}, \"\n",
    "                f\"subarea={self.subarea}, seccion={self.seccion}, poderes={self.poderes}, \"\n",
    "                f\"entidad={self.entidad}, capitulo={self.capitulo}, subcapitulo={self.subcapitulo}, \"\n",
    "                f\"unidad_ejecutora={self.unidad_ejecutora}, denominacion={self.denominacion}, \"\n",
    "                f\"codigo={self.codigo})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parsing\n",
    "filtered_lines = [line for line in lines if line.count('|') == 12]\n",
    "filtered_lines = filtered_lines[3:-1]\n",
    "organizations = []\n",
    "\n",
    "for line in filtered_lines:\n",
    "    line = line.strip()[1:-1] ## Remove \"|\" from the start and end.\n",
    "    result  = scripts.parse(line)\n",
    "    \n",
    "\n",
    "    organizations.append(Organization(**result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Takes 'organizations' data; and create a new parquet dataset.\n",
    "\n",
    "Needs:\n",
    "- Store multiple datasets / 'json schemas'.\n",
    "- Can have complex data (nested).\n",
    "- Use gzip + json file with all the schemas for easy reading.\n",
    "- Dataset can only be generated from a tag.\n",
    "\n",
    "Tools:\n",
    "- Gzip\n",
    "- Apache Parquet vs Apache Avro vs Apache ORC  or JSON.\n",
    "- ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.gnu.org/software/gzip/manual/gzip.html\n",
    "- https://avro.apache.org/\n",
    "- https://www.json.org/json-en.html\n",
    "- https://orc.apache.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open('result.log.gz', 'wb') as handler:\n",
    "#     handler.writ4e(\"abc\")\n",
    "\n",
    "data  =  scripts.dataset.Dataset()\n",
    "data.name     = \"prueba\"\n",
    "data.records  = organizations\n",
    "data.schema   = \"{}\"\n",
    "data.metadata = \"{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schema\n",
    "\n",
    "## /data\n",
    "## index\n",
    "\n",
    "# print(pydantic.TypeAdapter(Organization).json_schema())\n",
    "\n",
    "# index  = {[\n",
    "#     {\n",
    "#         name: ..\n",
    "#         schema: ...\n",
    "#         data:  id\n",
    "#     } \n",
    "# ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import shutil\n",
    "import tempfile\n",
    "from dataclasses import asdict\n",
    "\n",
    "def save(data):\n",
    "    \"\"\"\n",
    "        Save the `data.schema` as a JSON file and the `data.records` as `data.json` in a temporary folder.\n",
    "        Then, compress the contents of the folder into a single `.gz` archive.\n",
    "\n",
    "        Args:\n",
    "            data (object): An object with the following attributes:\n",
    "                - `name` (str): The name to use for the output files.\n",
    "                - `schema` (dict): The schema to be saved as `<data.name>.schema.json`.\n",
    "                - `records` (list): A list of dataclass instances to be serialized as `data.json`.\n",
    "\n",
    "        Results:\n",
    "            A `.gz` compressed file containing a folder with:\n",
    "                - `schema.json`: The saved schema data.\n",
    "                - `data.json`: The serialized records.\n",
    "                -  `metadata.json`: A metadata file.\n",
    "            The `.gz` file will contain only the files, not the folder structure.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Validate input\n",
    "    if not hasattr(data, 'name') or not hasattr(data, 'schema') or not hasattr(data, 'records'):\n",
    "        raise ValueError(\"The input data must have 'name', 'schema', and 'records' attributes.\")\n",
    "    \n",
    "    if not isinstance(data.name, str):\n",
    "        raise ValueError(\"'data.name' must be a string.\")\n",
    "    \n",
    "    if not isinstance(data.schema, str):\n",
    "        raise ValueError(\"'data.schema' must be a string.\")\n",
    "    \n",
    "\n",
    "    if not isinstance(data.metadata, str):\n",
    "        raise ValueError(\"'data.metadata' must be a string.\")\n",
    "    \n",
    "    if not isinstance(data.records, list):\n",
    "        raise ValueError(\"'data.records' must be a list.\")\n",
    "    \n",
    "    # Create a temporary folder\n",
    "    temp_folder = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        # Save schema as <data.name>.schema.json\n",
    "        schema_file_path = os.path.join(temp_folder, f\"{data.name}.schema.json\")\n",
    "        with open(schema_file_path, 'w') as handler:\n",
    "            json.dump(data.schema, handler, indent=4)\n",
    "        \n",
    "        # Save records as data.json\n",
    "        records_file_path = os.path.join(temp_folder, \"data.json\")\n",
    "        with open(records_file_path, 'w') as handler:\n",
    "            json.dump([asdict(record) for record in data.records], handler, indent=4)\n",
    "\n",
    "        # Save records as metadata.json\n",
    "        metadata_file_path = os.path.join(temp_folder, \"metadata.json\")\n",
    "        with open(metadata_file_path, 'w') as handler:\n",
    "            json.dump(data.metadata, handler, indent=4)\n",
    "        \n",
    "        # Define the output gzip file path\n",
    "        gzip_file_path = f\"{data.name}.ldata.gz\"\n",
    "\n",
    "        archive_path = shutil.make_archive(gzip_file_path, 'gztar', temp_folder,  base_dir='.')\n",
    "\n",
    "        print(f\"Data saved successfully to {archive_path}\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up: remove the temporary folder and its contents\n",
    "        # shutil.rmtree(temp_folder)\n",
    "        print(temp_folder)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Data saved successfully to <span style=\"color: #800080; text-decoration-color: #800080\">/home/dbremont/Code/Laboratorium/research/burocracia/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">prueba.ldata.gz.tar.gz</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Data saved successfully to \u001b[35m/home/dbremont/Code/Laboratorium/research/burocracia/\u001b[0m\u001b[95mprueba.ldata.gz.tar.gz\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">/tmp/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">tmpd2vm89o6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m/tmp/\u001b[0m\u001b[95mtmpd2vm89o6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Listado de Organismos](https://www.sismap.gob.do/GestionPublica/Organismos)\n",
    "\n",
    "- [Informacin General de RD](https://www.presidencia.gob.do/acerca-de-rd/informacion-general)\n",
    "\n",
    "- [Consulta de Organismos](https://map.gob.do/COEDOM/Home/Search)\n",
    "\n",
    "- https://sismap.gob.do/\n",
    "\n",
    "- https://www.sismap.gob.do/Municipal/\n",
    "\n",
    "- [Clasificadores Presupuestarios](https://www.digepres.gob.do/publicaciones/clasificadores-presupuestarios/)\n",
    "\n",
    "- [Organismos del Estado Dominicano](https://www.sismap.gob.do/Central/Home/About)\n",
    "\n",
    "- [Clasificación de los Organismos de la Administración del Estado Dominicano](https://map.gob.do/COEDOM/Home/Clasificacion)\n",
    "\n",
    "- [Miguel Collado: RD es el cuarto país de América Latina con mayor porcentaje de empleados públicos](https://www.diariolibre.com/economia/macroeconomia/2024/06/20/cuanto-gasta-el-gobierno-en-la-nomina-publica/2761319)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
